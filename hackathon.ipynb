{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1ae677",
   "metadata": {},
   "source": [
    "# SAT Machine Learning Hackathon Team $\\Sigma \\Omega$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The following option ensures that Pandas treats string as string and not \"objects\"\n",
    "# This is something that will be default behaviour in Pandas 3.0, but you can already\n",
    "# switch it on.\n",
    "pd.options.future.infer_string = True\n",
    "\n",
    "# Import the dataset, casting some of the categorical features that are stored as numbers\n",
    "# as strings, rather than allowing Pandas to assuming that they are meant to be\n",
    "# integers or floats.\n",
    "df = (\n",
    "    pd.read_csv(\n",
    "        'data/train.csv', \n",
    "        dtype={\n",
    "            'attendance_category': 'str', \n",
    "            'treatment_function_code': 'str', \n",
    "            'palliative_care_description': 'str',\n",
    "            }\n",
    "        )\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at our data. Notice that it shows the first dozen columns and \n",
    "# then the last dozen...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32257a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .iloc means that we can take vertical slices of our DataFrame, so that\n",
    "# we can look at all of our columns over a few code cells.\n",
    "# The syntax is df.iloc[rows,columns]. The \":\"\" for rows means \"everything\" and the\n",
    "# \":10\" means \"up to the 10th column\".\n",
    "\n",
    "df.iloc[:,:10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 11th to the 20th columns\n",
    "df.iloc[:,11:20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 21st to the 30th columns\n",
    "df.iloc[:,21:30].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f871e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column 31 to the last column\n",
    "df.iloc[:,31:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many rows and columns there are\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give us the data types and how many values are not null\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c1e34",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb14cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a nifty way of getting the percentage of values that are\n",
    "# missing from each column\n",
    "df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple visualisation of how many values are missing from each column.\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    " \n",
    "(1 - df.isnull().mean()).abs().plot.bar(ax=ax)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b050d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the \"columns\" attribute of the dataframe to return the column names,\n",
    "# which can be copied into your code when exploring the data.\n",
    "# Note that this isn't strictly a Python \"list\". You would need to cast it as\n",
    "# such: list(df.columns)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd68f7f6",
   "metadata": {},
   "source": [
    "### Creating charts to explore data fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb40c98",
   "metadata": {},
   "source": [
    "Here we are going to create a chart of how many values there are for each category in \"acuity_desc\". Firstly, we create a DataFrame and then we can put it into a simple `seaborn` chart, using `matplotlib` to tweak the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc10cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuity = pd.DataFrame(df.acuity_desc.value_counts())\n",
    "\n",
    "acuity.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d680da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4370067",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "sns.barplot(acuity, x='acuity_desc', y='count', ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c492c9",
   "metadata": {},
   "source": [
    "Creating a facet grid to look at the distribution of multiple numeric values.\n",
    "\n",
    "_We didn't all get to this on the Hackathon day, but here are is a way to do it since it's a handy way to appraise multiple fields in one go._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d01c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take some numeric fields that have a bit of a range to them.\n",
    "\n",
    "num_fields_facet = ['departure_time_since_arrival','lsoa_site_of_treatment_distance','age_at_arrival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols= len(num_fields_facet), figsize=(12,4))\n",
    "\n",
    "for i, col in enumerate(num_fields_facet):\n",
    "    sns.histplot(data=df, x=col, ax=axes[i])\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "plt.suptitle('Numerical Feature Distributions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2cbd1",
   "metadata": {},
   "source": [
    "A version that looks at the value counts of categorical fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is how to select all of the categorical fields in the dataset,\n",
    "# but we will select a few on this occasion since our dataset is large\n",
    "# and has a large number of categorical features.\n",
    "\n",
    "# get the categorical (string) fields in the dataset.\n",
    "# cat_fields_facet = list(df.select_dtypes(str).columns)\n",
    "\n",
    "cat_fields_facet = [\n",
    "    'ethnic_category',\n",
    "    'patient_status',\n",
    "    'acuity_desc',\n",
    "    'care_home_status',\n",
    "    'destination_desc',\n",
    "    'arrival_mode_desc'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60504a3",
   "metadata": {},
   "source": [
    "Plotting the grid of charts. Note that it gets quite big due to the length of the category names. You may wish to do some processing to reduce the length of the categories, possibly by encoding them with single letters or numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(cat_fields_facet)               # number of features being examined\n",
    "ncols = 3                               # number of columns in the grid\n",
    "nrows = np.ceil(n/ncols).astype(int)    # number of rows required to cover all the features, accounting for the number of columns.\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 8*nrows))   # set your plot area, figsize=(width,height)\n",
    "\n",
    "axes = axes.flatten()   # this is needed because the output of the rows/columns calculation is a numpy array, which\n",
    "                        # can't be used in an Axes object.\n",
    "\n",
    "for ax, col in zip(axes, cat_fields_facet):\n",
    "    counts = df[col].value_counts().reset_index()\n",
    "    counts.columns = [col, \"count\"]\n",
    "\n",
    "    sns.barplot(data=counts, x=col, y=\"count\", ax=ax)\n",
    "    ax.set_title(f\"Value Counts for {col}\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "plt.suptitle('Categorical Feature Distributions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de9516",
   "metadata": {},
   "source": [
    "You could also look at how categories of specific features correlated with the target. Here are some charts Jonas produced during the hackathon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "fraction_df = (\n",
    "    df.groupby('long_term_condition_count_number')['frequent_attender']\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "fraction_df.plot(\n",
    "\tkind='bar',\n",
    "\tstacked=True,\n",
    "\tfigsize=(10, 6),\n",
    "\tcolor=[\"#0062FF\", '#DD8452']\n",
    ")\n",
    "\n",
    "plt.legend(title='Frequent Attender')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.legend(title='Frequent Attender', labels=['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_df2 = (\n",
    "\tdf.groupby('destination_desc')['frequent_attender']\n",
    "\t.value_counts(normalize=True)\n",
    "\t.unstack()\n",
    ")\n",
    "\n",
    "fraction_df2.plot(\n",
    "\tkind='barh',  # horizontal bar plot\n",
    "\tstacked=True,\n",
    "\tfigsize=(10, 7),\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.legend(loc='upper left',title='Frequent Attender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c8093f",
   "metadata": {},
   "source": [
    "### Looking at the value counts for each feature individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stated_gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0124c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.living_alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a974f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.acutely_unwell_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.all_long_term_condition_count_number.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12c972",
   "metadata": {},
   "source": [
    "### Getting the list of columns, so that they can be easily copied into the list of columns to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29342f1b",
   "metadata": {},
   "source": [
    "### Dropping the columns that we don't want to keep as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\n",
    "    'nhs_number',\n",
    "    'organisation_code_provider',\n",
    "    'organisation_code_commissioner',\n",
    "    'lsoa_11',\n",
    "    'index_of_multiple_deprivation_description',\n",
    "    'accommodation_status_desc',\n",
    "    'treatment_function_code',\n",
    "    'acuity_code_approved',\n",
    "    'gp_practice',\n",
    "    'gp_practice_code', # high cardinality categorical variable. Take out for now and bring back for CatBoost\n",
    "    'palliative_care_description',\n",
    "    'care_home_name',\n",
    "    'patient_status', # leaks data i.e. if someone has died, can they reattend?\n",
    "    'all_long_term_conditions',\n",
    "    'segmentation_bridges_to_health_description',\n",
    "    'patient_registration_status',\n",
    "    'all_long_term_condition_count',\n",
    "    'attendance_category',\n",
    "    'living_alone'\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7eb022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed041593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.palliative_care_flag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e195faf",
   "metadata": {},
   "source": [
    "Gender was a column that was imported as float values, but it is meant to be categorical. The following cell converts the values to categories, dealing with any unknown values. Converting any NaN values (i.e. Python's equivalent of NULL) into a string results in a 'nan' string, which we need to convert back into an _empty_ string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da23f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stated_gender'] = df['stated_gender'].astype(str)\n",
    "df['stated_gender'] = df['stated_gender'].replace('nan','X') # unknown is meant to be X. 9 is unable to classify as male or female.\n",
    "df['stated_gender'] = df['stated_gender'].str.replace('.0','',regex=False) # regex = False treats the \".\" literally and not as a regex character.\n",
    "df['stated_gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9370c28",
   "metadata": {},
   "source": [
    "### Dropping rows containing missing values\n",
    "\n",
    "We dropped all rows containing NaN (NULL) values, rather than dealing with the missing values, which requires a lot more thought than we had time for. We were still left with a healthy amount of data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf66f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60cb0d9",
   "metadata": {},
   "source": [
    "Check how many rows and columns we are left with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88198a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802ce7d",
   "metadata": {},
   "source": [
    "Identify our target $y$ and feature $X$ columns. The target is the thing you are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eda2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['frequent_attender']\n",
    "X = df.drop(columns=['frequent_attender'])\n",
    "X_features = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144773a2",
   "metadata": {},
   "source": [
    "### The train-test split\n",
    "\n",
    "This is where we did our train-test split. Usually this is best done _after_ preprocessing and feature engineering has been completed, so that you end up with the same feature columns in both the train and test sets. It wasn't the end of the world, it just meant a little bit of extra work to get things in order.\n",
    "\n",
    "Ed got a bit confused since he had recently heard that you need to do the split _before_ any preprocessing / feature engineering, but he missed the nuance that you ought to do the split before any imputation of values that use something like the mean value, because using the whole dataset for this leaks some information from what will become the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecaa60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebd38b",
   "metadata": {},
   "source": [
    "### Preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e09c1",
   "metadata": {},
   "source": [
    "Converting the 'arrival_datetime' field into the datetime data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['arrival_datetime'] = pd.to_datetime(X_train['arrival_datetime'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50480b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['arrival_datetime'] = pd.to_datetime(X_test['arrival_datetime'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd49297",
   "metadata": {},
   "source": [
    "Lucy suggested creating an \"arrival outside of core GP hours\" flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['arrival_outside_of_core_gp_hours'] = X_train['arrival_datetime'].dt.hour.apply(lambda x: 1 if (x < 8) | (x >= 18) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['arrival_outside_of_core_gp_hours'] = X_test['arrival_datetime'].dt.hour.apply(lambda x: 1 if (x < 8) | (x >= 18) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5cf33",
   "metadata": {},
   "source": [
    "Create a flag to see whether the original attendance was at the weekend. Could it lead to be treated and assessed differently, with knock-on effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"is_weekend\"] = X_test['arrival_datetime'].dt.dayofweek >= 5 # creates a Boolean flag\n",
    "\n",
    "X_test[\"is_weekend\"] = X_test[\"is_weekend\"].astype(int) # converts the Boolean to a 1 or 0 (keep thing numeric for consistency)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ebc0b",
   "metadata": {},
   "source": [
    "Then we dropped the 'arrival_datetime' field to remove a field that would be predicting the same variation. In hindsight, it might have been better to leave it in for models such as CatBoost, which can handle greater numbers of features & may have been able to find some signal in the arrival datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996dfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['arrival_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7637f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(columns=['arrival_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd5653",
   "metadata": {},
   "source": [
    "We created a \"70 years old or older\" flag. Paul D identified a correlation between this age band and being a frequent attender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dedaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_over_70(row):\n",
    "    if row['age_at_arrival'] > 69:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066591db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['over_70'] = X_train.apply(is_over_70, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['over_70'] = X_test.apply(is_over_70, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8edb5",
   "metadata": {},
   "source": [
    "James suggested a \"four-hour wait\" flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_hour_wait(row):\n",
    "    if row['departure_time_since_arrival'] > 240:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "   \n",
    "X_train['four_hr_Wait'] = X_train.apply(four_hour_wait, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['four_hr_Wait'] = X_test.apply(four_hour_wait, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6325a81",
   "metadata": {},
   "source": [
    "Have a look at which columns we have so far and check they are consistent across train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3286e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95046c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed443002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff0270",
   "metadata": {},
   "source": [
    "### One-hot encoding categorical features.\n",
    "\n",
    "We one-hot encoded some categorical features so that they could be treated as numeric fields. This creates a separate column for each category and then records True / False to say whether the value for that row of data falls into that category.\n",
    "\n",
    "We set a prefix to make the generated columns easily attributable to the original feature. We also set the data type as integer so that it returns a 1 or 0, rather than True / False.\n",
    "\n",
    "This process generates a separate DataFrame, which needs to be concatenated with the X data (needs to be done with X_train and X_test, if you have already split the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoded = pd.get_dummies(X_train['stated_gender'], prefix='gender_code', dtype=int)\n",
    "\n",
    "X_train = pd.concat([X_train, gender_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encoded_test = pd.get_dummies(X_test['stated_gender'], prefix='gender_code', dtype=int)\n",
    "\n",
    "X_test = pd.concat([X_test, gender_encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe94229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8414adb",
   "metadata": {},
   "source": [
    "### Correlation of numeric features\n",
    "\n",
    "At this stage, we could have looked at the correlation between numeric features, to see whether there are any that we could have removed.\n",
    "\n",
    "Features that correlate highly explain the same variation in the data, and the effect of this can be to _underestimate_ the effect of those features.\n",
    "\n",
    "We can use `df.corr()` to get a correlation table, or we can use a heatmap visualisation, which will highlight high correlation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ed8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train.select_dtypes('number')\n",
    "\n",
    "X_train_numeric.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2d6dd",
   "metadata": {},
   "source": [
    "Thanks to Emile for the following heatmap. The default in `seaborn` returns the entire correlation table colour-coded, but this effectively duplicates the pairs. Emile's version trims off the top-right corner, leaving each feature pair just once.\n",
    "\n",
    "Ed was going to use a library called `yellowbrick`, which was designed specifically to produce visualisations relating to `scikit-learn` uses. However, it requires a dependency that has recently been deprecated & it would have taken too long to find a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot covariance rankings\n",
    "corr = X_train_numeric.corr()  # Compute correlation matrix\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool), k=1) # Make mask for the upper triangle\n",
    "f, ax = plt.subplots(figsize=(75, 15)) # Set matplotlib figure \n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True) # Generate a custom diverging colormap\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "ax = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0, annot = True,\n",
    "                 annot_kws={\"size\": 8}, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Correlation Matrix', fontsize=15, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df48586",
   "metadata": {},
   "source": [
    "You can see that some pairs such as \"segmentation_bridges_to_health\" and \"long_term_condition_number\" correlate quite highly. Do we need \"long_term_condition_count_number\" _and_ \"long_term_condition_count_number\"? For simpler models, it would probably be best to drop \"age_at_arrival\" after having created the \"over_70\" flag.\n",
    "\n",
    "Sometimes, when you get mutually exclusive categories, it can be worth dropping one of them and renaming the one that you are left with. For example, here you can see that \"gender_code_1\" (male) and \"gender_code_2\" (female) are very strongly negatively correlated with each other, as you would expect. You could drop one or the other and have a single \"is_male\" or \"is_female\" feature since the negative would imply the other. In actual fact, there are some records for patients with \"gender_code_9\" (indeterminate), so we probably shouldn't do this with our data since we could lose that information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eccd76",
   "metadata": {},
   "source": [
    "# Creating our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b416ef4",
   "metadata": {},
   "source": [
    "### Dummy Classifier\n",
    "\n",
    "Acts as a baseline. Predicts the mode target class (in this case \"0\" for \"not a frequent attender\") every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dumb_dumb = DummyClassifier()\n",
    "\n",
    "dumb_dumb.fit(X_train,y_train)\n",
    "\n",
    "dumb_dumb_probs = dumb_dumb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "brier_score_loss(y_test, dumb_dumb_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd5e51",
   "metadata": {},
   "source": [
    "# Logistic regression example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a26635",
   "metadata": {},
   "source": [
    "These features were suggested by Paul D as being the most likely to predict whether someone will be a frequent attender, based on his population health expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad57977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_feats = ['index_of_multiple_deprivation','over_70','segmentation_bridges_to_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab001b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train = X_train[log_feats] # restrict train and test to just the suggested features.\n",
    "log_test = X_test[log_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression() # instantiate a logistic regression model\n",
    "\n",
    "lgr.fit(log_train,y_train) # fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = lgr.predict_proba(log_test)[:, 1] # get the prediction probabilities needed to calculate the Brier Score Loss\n",
    "\n",
    "brier_score_loss(y_test, log_probs) # calculate the Brier Score Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98536532",
   "metadata": {},
   "source": [
    "We could then have a look at the feature coefficients to see which had the biggest effect on the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lgr.coef_[0] # Just returns a numpy array of coefficients without the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gives us a table that includes the feature names.\n",
    "# \"coeffiecient\" gives the value, including whether it is positive or negative.\n",
    "# \"abs_coefficient\" gives the absolute value so that we can compare the size of the effect more intuitively.\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': log_feats,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "}).sort_values(by='abs_coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1c55d",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "We will throw as many numeric features at it as possible.\n",
    "\n",
    "First, we want to see whether we can group some of the high-cardinality categorical features so that we can one-hot encode some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d282e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = X_train.select_dtypes(include='string').columns.tolist()\n",
    "\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d905c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.care_home_status.value_counts() # low cardinality already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.ethnic_category.value_counts() # middling cardinality. Records fall overwhelmingly into one category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5eb306",
   "metadata": {},
   "source": [
    "We reduced the number of ethnicity categories by grouping them into white, non-white and unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89426839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethnicity_grouping(row):\n",
    "    if row['ethnic_category'] == 'A':\n",
    "        return 'white'\n",
    "    elif row['ethnic_category'] == '99':\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return 'non-white'\n",
    "\n",
    "X_train['ethnicity_group'] = X_train.apply(ethnicity_grouping, axis=1)\n",
    "X_test['ethnicity_group'] = X_test.apply(ethnicity_grouping, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a34ae",
   "metadata": {},
   "source": [
    "We dropped the original feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26674748",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['ethnic_category'])\n",
    "X_test = X_test.drop(columns=['ethnic_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d8cfc",
   "metadata": {},
   "source": [
    "Most of the records fell into two arrival mode categories, so we groupen them by those two plus \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f91519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.arrival_mode_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd531cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrival_mode_grouping(row):\n",
    "    if row['arrival_mode_desc'] == 'Arrival by own transport (finding)':\n",
    "        return 'own_transport'\n",
    "    elif row['arrival_mode_desc'] == 'Arrival by emergency road ambulance (finding)':\n",
    "        return 'ambulance'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "X_train['arrival_mode_grouping'] = X_train.apply(arrival_mode_grouping, axis=1)\n",
    "X_test['arrival_mode_grouping'] = X_test.apply(arrival_mode_grouping, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad97435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['arrival_mode_desc'])\n",
    "X_test = X_test.drop(columns=['arrival_mode_desc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b5352",
   "metadata": {},
   "source": [
    "Again, discharge status was mainly in one category, so we created a \"completed_treatment\" numeric flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.discharge_status_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def completed_treatment(row):\n",
    "    if row['discharge_status_desc'] == 'Treatment completed (situation)':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "X_train['completed_treatment'] = X_train.apply(completed_treatment, axis=1)\n",
    "X_test['completed_treatment'] = X_test.apply(completed_treatment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['discharge_status_desc'])\n",
    "X_test = X_test.drop(columns=['discharge_status_desc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fcbf7d",
   "metadata": {},
   "source": [
    "Because we were running out of time on the day, some of the categorical features were left as they were. They will be used when we come to the CatBoost model, which is capable of dealing with high-cardinality categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.destination_desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f174962",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.acuity_desc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7648e9f7",
   "metadata": {},
   "source": [
    "Now we will one-hot encode the new categorical groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_encoded = pd.get_dummies(X_train['ethnicity_group'], prefix='ethnicity_group', dtype=int)\n",
    "\n",
    "X_train = pd.concat([X_train, ethnicity_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_encoded_test = pd.get_dummies(X_test['ethnicity_group'], prefix='ethnicity_group', dtype=int)\n",
    "\n",
    "X_test = pd.concat([X_test, ethnicity_encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['ethnicity_group'])\n",
    "X_test = X_test.drop(columns=['ethnicity_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_mode_encoded = pd.get_dummies(X_train['arrival_mode_grouping'], prefix='arrival_mode_grouping', dtype=int)\n",
    "\n",
    "X_train = pd.concat([X_train, arrival_mode_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_mode_encoded_test = pd.get_dummies(X_test['arrival_mode_grouping'], prefix='arrival_mode_grouping', dtype=int)\n",
    "\n",
    "X_test = pd.concat([X_test, arrival_mode_encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['arrival_mode_grouping'])\n",
    "X_test = X_test.drop(columns=['arrival_mode_grouping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_treatment_encoded = pd.get_dummies(X_train['completed_treatment'], prefix='completed_treatment', dtype=int)\n",
    "\n",
    "X_train = pd.concat([X_train, completed_treatment_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_treatment_encoded_test = pd.get_dummies(X_test['completed_treatment'], prefix='completed_treatment', dtype=int)\n",
    "\n",
    "X_test = pd.concat([X_test, completed_treatment_encoded_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['completed_treatment'])\n",
    "X_test = X_test.drop(columns=['completed_treatment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c217193",
   "metadata": {},
   "source": [
    "Now we will start building the Random Forest Classifier model, using only the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feats = X_train.select_dtypes('number').columns\n",
    "\n",
    "rf_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = X_train[rf_feats]\n",
    "rf_test = X_test[rf_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(rf_train, y_train)\n",
    "rf_probs = rf.predict_proba(rf_test)[:, 1]\n",
    "brier_score_loss(y_test, rf_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aece34d",
   "metadata": {},
   "source": [
    "This appears to be worse than the dummy classifier. This could be because it is struggling with the imbalanced target class, where there are far more patients who are not frequent attenders than are. The dummy classifier potentially did better simply because it predicted \"0\" all the time.\n",
    "\n",
    "This is where we might want to score each model for accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7ab92",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "Proportion of correct predictions from all predictions:\n",
    "\n",
    "$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "Not sufficient on its own, because if you have 1 positive in 10,000, you could get very high accuracy by predicting negative all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557cd904",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "\n",
    "Also known as _sensitivity_. The percentage of positive values correctly classified.\n",
    "\n",
    "$\\text{Recall} = \\frac{TP}{TP + FN}$\n",
    "\n",
    "_How many relevant results are returned?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8762257",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "Percentage of positive predictions that were correct.\n",
    "\n",
    "$\\text{Precision} = \\frac{TP}{TP + FP}$ \n",
    "\n",
    "_How relevant are the results?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58970e",
   "metadata": {},
   "source": [
    "#### F1\n",
    "\n",
    "\"Combined\" precision and recall. It's the _harmonic mean_ of the two\n",
    "\n",
    "$\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "\n",
    "or\n",
    "\n",
    "$\\text{F1 Score} = 2 \\times \\frac{TP}{2TP + FP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426eba0",
   "metadata": {},
   "source": [
    "### Feature Importances. \n",
    "\n",
    "They indicate that treatment distance was considered the most important, which is surprising. Age and IMD still come out quite high. The model probably would have performed better if we had dropped more of the correlating features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, val in sorted(\n",
    "    zip(\n",
    "        rf_feats, \n",
    "        rf.feature_importances_\n",
    "        ), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True):\n",
    "        print(f'{col:20}{val:10.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65f4ba",
   "metadata": {},
   "source": [
    "# Catboost\n",
    "\n",
    "This will use all of the remaining features in X_train (rather than just the numeric features). We will also drop \"age_at_arrival\" and just keep the \"over_70\" flag.\n",
    "\n",
    "We will just use the default settings for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114cfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=['age_at_arrival','stated_gender']) # stated_gender can go, too, because we have one-hot encoded it\n",
    "X_test = X_test.drop(columns=['age_at_arrival','stated_gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['destination_desc', 'acuity_desc', 'care_home_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9517166",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(cat_features=categorical_features)\n",
    "cat.fit(X_train, y_train)\n",
    "cat_probs = cat.predict_proba(X_test)[:, 1]\n",
    "brier_score_loss(y_test, cat_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b1328",
   "metadata": {},
   "source": [
    "Quickly try hyperparameter tuning with Optuna. The number of iterations has been fixed, and the number of trials (`n_trials`) and `early_stopping_rounds` have been set quite low, otherwise it takes quite a long time to run on this large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd59d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': 100,\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 1e-3, 10),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 50),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
    "        'leaf_estimation_method': trial.suggest_categorical('leaf_estimation_method', ['Newton', 'Gradient']),\n",
    "    }\n",
    "    \n",
    "    catTuna = CatBoostClassifier(**param, verbose=0, cat_features=categorical_features)\n",
    "    catTuna.fit(X_train, y_train, early_stopping_rounds=20) # stop after 20 rounds if the score stops improving.\n",
    "    probTuna = cat.predict_proba(X_test)[:, 1]\n",
    "    brierCat = brier_score_loss(y_test, probTuna)\n",
    "    return brierCat\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Get best parameters\n",
    "best_paramsTuna = study.best_params\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_cat = CatBoostClassifier(**best_paramsTuna, cat_features=categorical_features, verbose=0)\n",
    "best_cat.fit(X_train, y_train)\n",
    "final_probTuna = best_cat.predict_proba(X_test)[:, 1]\n",
    "finalBrierCat = brier_score_loss(y_test, final_probTuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef971d",
   "metadata": {},
   "source": [
    "It didn't do any better than the default parameters, probably because we only let it run a few iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
